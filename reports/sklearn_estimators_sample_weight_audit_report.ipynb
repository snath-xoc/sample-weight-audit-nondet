{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit-learn sample_weight compliance report\n",
    "\n",
    "This notebook runs compliance tests on all scikit-learn estimators. Estimator as inspected to check whether they are expected to have a stochastic fit or not. If the fit is stochastic, a dedicated statistical test is performed, otherwise a deterministic estimator check is run instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "System:\n",
      "    python: 3.12.4 | packaged by conda-forge | (main, Jun 17 2024, 10:13:44) [Clang 16.0.6 ]\n",
      "executable: /Users/shrutinath/micromamba/envs/scikit-learn/bin/python\n",
      "   machine: macOS-14.3-arm64-arm-64bit\n",
      "\n",
      "Python dependencies:\n",
      "      sklearn: 1.8.dev0\n",
      "          pip: 24.0\n",
      "   setuptools: 75.8.0\n",
      "        numpy: 2.0.0\n",
      "        scipy: 1.15.3\n",
      "       Cython: 3.0.10\n",
      "       pandas: 2.2.2\n",
      "   matplotlib: 3.9.0\n",
      "       joblib: 1.4.2\n",
      "threadpoolctl: 3.5.0\n",
      "\n",
      "Built with OpenMP: True\n",
      "\n",
      "threadpoolctl info:\n",
      "       user_api: blas\n",
      "   internal_api: openblas\n",
      "    num_threads: 8\n",
      "         prefix: libopenblas\n",
      "       filepath: /Users/shrutinath/micromamba/envs/scikit-learn/lib/libopenblas.0.dylib\n",
      "        version: 0.3.27\n",
      "threading_layer: openmp\n",
      "   architecture: VORTEX\n",
      "\n",
      "       user_api: openmp\n",
      "   internal_api: openmp\n",
      "    num_threads: 8\n",
      "         prefix: libomp\n",
      "       filepath: /Users/shrutinath/micromamba/envs/scikit-learn/lib/libomp.dylib\n",
      "        version: None\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "sklearn.show_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect import signature\n",
    "import traceback\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from sklearn.utils import all_estimators\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "import threadpoolctl\n",
    "\n",
    "from sample_weight_audit import check_weighted_repeated_estimator_fit_equivalence\n",
    "from sample_weight_audit.sklearn_stochastic_params import STOCHASTIC_FIT_PARAMS\n",
    "\n",
    "# HistGradientBoostingClassifier trashes the OpenMP thread pool on repeated\n",
    "# small fits.\n",
    "threadpoolctl.threadpool_limits(limits=1, user_api=\"openmp\")\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)  # division by zero in AdaBoost\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)  # liblinear can fail to converge\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)  # KBinsDiscretizer with collapsed bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "ESTIMATORS_TO_SKIP = [\n",
    "    LogisticRegressionCV,  # too slow and already somewhat tested by LogisticRegression\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠ ARDRegression does not support sample_weight\n",
      "Evaluating AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
      "                                                    min_weight_fraction_leaf=0.1))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:05<00:00, 18.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ AdaBoostClassifier: (pvalue: 0.211)\n",
      "Evaluating AdaBoostRegressor(estimator=DecisionTreeRegressor(max_features=0.5,\n",
      "                                                  min_weight_fraction_leaf=0.1))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 22.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ AdaBoostRegressor: (pvalue: 0.001)\n",
      "⚠ AdditiveChi2Sampler does not support sample_weight\n",
      "⚠ AffinityPropagation does not support sample_weight\n",
      "⚠ AgglomerativeClustering does not support sample_weight\n",
      "Evaluating BaggingClassifier(estimator=LogisticRegression())\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 34.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ BaggingClassifier: (pvalue: 0.000)\n",
      "Evaluating BaggingRegressor(estimator=Ridge())\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 90.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ BaggingRegressor: (pvalue: 0.000)\n",
      "Evaluating BayesianRidge()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 633.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ BayesianRidge: (pvalue: 1.000)\n",
      "Evaluating BernoulliNB()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 440.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ BernoulliNB: (pvalue: 1.000)\n",
      "⚠ BernoulliRBM does not support sample_weight\n",
      "⚠ Binarizer does not support sample_weight\n",
      "⚠ Birch does not support sample_weight\n",
      "Evaluating BisectingKMeans(n_clusters=10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 195.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ BisectingKMeans: (pvalue: 1.000)\n",
      "⚠ CCA does not support sample_weight\n",
      "Evaluating CalibratedClassifierCV()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 87.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CalibratedClassifierCV: (pvalue: 1.000)\n",
      "Evaluating CategoricalNB()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ CategoricalNB() error with: index 7 is out of bounds for axis 1 with size 7\n",
      "⚠ ClassifierChain does not support sample_weight\n",
      "⚠ ColumnTransformer does not support sample_weight\n",
      "Evaluating ComplementNB()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 450.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ComplementNB: (pvalue: 1.000)\n",
      "Evaluating DBSCAN()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DBSCAN: (pvalue: 1.000)\n",
      "Evaluating DecisionTreeClassifier(max_features=0.5, min_weight_fraction_leaf=0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 562.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DecisionTreeClassifier: (pvalue: 0.282)\n",
      "Evaluating DecisionTreeRegressor(max_features=0.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 954.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DecisionTreeRegressor: (pvalue: 0.583)\n",
      "⚠ DictVectorizer does not support sample_weight\n",
      "⚠ DictionaryLearning does not support sample_weight\n",
      "Evaluating DummyClassifier(strategy='stratified')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 866.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DummyClassifier: (pvalue: 0.024)\n",
      "Evaluating DummyRegressor()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1125.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DummyRegressor: (pvalue: 1.000)\n",
      "Evaluating ElasticNet(selection='random')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 779.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ElasticNet: (pvalue: 0.583)\n",
      "Evaluating ElasticNetCV(selection='random')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 63.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ElasticNetCV: (pvalue: 0.282)\n",
      "Evaluating ExtraTreeClassifier()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 669.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ExtraTreeClassifier: (pvalue: 0.968)\n",
      "Evaluating ExtraTreeRegressor()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1020.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ExtraTreeRegressor: (pvalue: 0.368)\n",
      "Evaluating ExtraTreesClassifier()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:06<00:00, 14.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ExtraTreesClassifier: (pvalue: 0.815)\n",
      "Evaluating ExtraTreesRegressor()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:06<00:00, 15.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ExtraTreesRegressor: (pvalue: 0.282)\n",
      "⚠ FactorAnalysis does not support sample_weight\n",
      "⚠ FastICA does not support sample_weight\n",
      "⚠ FeatureAgglomeration does not support sample_weight\n",
      "⚠ FeatureHasher does not support sample_weight\n",
      "⚠ FeatureUnion does not support sample_weight\n",
      "⚠ FixedThresholdClassifier does not support sample_weight\n",
      "⚠ FunctionTransformer does not support sample_weight\n",
      "Evaluating GammaRegressor()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 555.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GammaRegressor: (pvalue: 1.000)\n",
      "Evaluating GaussianNB()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 359.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GaussianNB: (pvalue: 1.000)\n",
      "⚠ GaussianProcessClassifier does not support sample_weight\n",
      "⚠ GaussianProcessRegressor does not support sample_weight\n",
      "⚠ GaussianRandomProjection does not support sample_weight\n",
      "⚠ GenericUnivariateSelect does not support sample_weight\n",
      "Evaluating GradientBoostingClassifier(max_features=0.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GradientBoostingClassifier: (pvalue: 0.111)\n",
      "Evaluating GradientBoostingRegressor(max_features=0.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 34.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GradientBoostingRegressor: (pvalue: 0.006)\n",
      "⚠ HDBSCAN does not support sample_weight\n",
      "⚠ HashingVectorizer does not support sample_weight\n",
      "Evaluating HistGradientBoostingClassifier(max_features=0.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:28<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ HistGradientBoostingClassifier: (pvalue: 0.000)\n",
      "Evaluating HistGradientBoostingRegressor(max_features=0.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:12<00:00,  8.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ HistGradientBoostingRegressor: (pvalue: 0.000)\n",
      "Evaluating HuberRegressor()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 60.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ HuberRegressor: (pvalue: 1.000)\n",
      "⚠ IncrementalPCA does not support sample_weight\n",
      "⚠ Isomap does not support sample_weight\n",
      "Evaluating IsotonicRegression()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 663.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ IsotonicRegression: (pvalue: 1.000)\n",
      "Evaluating KBinsDiscretizer(encode='ordinal', quantile_method='averaged_inverted_cdf',\n",
      "                 subsample=50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 402.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ KBinsDiscretizer: (pvalue: 0.282)\n",
      "Evaluating KMeans(n_clusters=10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 433.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ KMeans: (pvalue: 1.000)\n",
      "⚠ KNNImputer does not support sample_weight\n",
      "⚠ KNeighborsClassifier does not support sample_weight\n",
      "⚠ KNeighborsRegressor does not support sample_weight\n",
      "⚠ KNeighborsTransformer does not support sample_weight\n",
      "⚠ KernelCenterer does not support sample_weight\n",
      "⚠ KernelPCA does not support sample_weight\n",
      "Evaluating KernelRidge()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 466.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ KernelRidge: (pvalue: 1.000)\n",
      "⚠ LabelBinarizer does not support sample_weight\n",
      "⚠ LabelEncoder does not support sample_weight\n",
      "⚠ LabelPropagation does not support sample_weight\n",
      "⚠ LabelSpreading does not support sample_weight\n",
      "⚠ Lars does not support sample_weight\n",
      "⚠ LarsCV does not support sample_weight\n",
      "Evaluating Lasso(selection='random')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1032.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Lasso: (pvalue: 1.000)\n",
      "Evaluating LassoCV(selection='random')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 54.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LassoCV: (pvalue: 0.702)\n",
      "⚠ LassoLars does not support sample_weight\n",
      "⚠ LassoLarsCV does not support sample_weight\n",
      "⚠ LassoLarsIC does not support sample_weight\n",
      "⚠ LatentDirichletAllocation does not support sample_weight\n",
      "⚠ LinearDiscriminantAnalysis does not support sample_weight\n",
      "Evaluating LinearRegression()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 849.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LinearRegression: (pvalue: 1.000)\n",
      "Evaluating LinearSVC(dual=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 171.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LinearSVC: (pvalue: 0.010)\n",
      "Evaluating LinearSVR(dual=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 461.70it/s]\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ LinearSVR: (pvalue: 0.000)\n",
      "⚠ LocallyLinearEmbedding does not support sample_weight\n",
      "Evaluating LogisticRegression(dual=True, max_iter=100000, solver='liblinear')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      " 41%|████      | 41/100 [00:00<00:00, 401.69it/s]/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      " 82%|████████▏ | 82/100 [00:00<00:00, 405.51it/s]/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "100%|██████████| 100/100 [00:00<00:00, 405.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ LogisticRegression: (pvalue: 0.000)\n",
      "Skipping LogisticRegressionCV\n",
      "Evaluating MLPClassifier()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:05<00:00, 18.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MLPClassifier: (pvalue: 0.702)\n",
      "Evaluating MLPRegressor()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 21.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MLPRegressor: (pvalue: 0.908)\n",
      "⚠ MaxAbsScaler does not support sample_weight\n",
      "⚠ MeanShift does not support sample_weight\n",
      "⚠ MinMaxScaler does not support sample_weight\n",
      "⚠ MiniBatchDictionaryLearning does not support sample_weight\n",
      "Evaluating MiniBatchKMeans(n_clusters=10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 179.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MiniBatchKMeans: (pvalue: 1.000)\n",
      "⚠ MiniBatchNMF does not support sample_weight\n",
      "⚠ MiniBatchSparsePCA does not support sample_weight\n",
      "⚠ MissingIndicator does not support sample_weight\n",
      "⚠ MultiLabelBinarizer does not support sample_weight\n",
      "⚠ MultiOutputClassifier failed to instantiate: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "⚠ MultiOutputRegressor failed to instantiate: MultiOutputRegressor.__init__() missing 1 required positional argument: 'estimator'\n",
      "⚠ MultiTaskElasticNet does not support sample_weight\n",
      "⚠ MultiTaskElasticNetCV does not support sample_weight\n",
      "⚠ MultiTaskLasso does not support sample_weight\n",
      "⚠ MultiTaskLassoCV does not support sample_weight\n",
      "Evaluating MultinomialNB()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 432.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MultinomialNB: (pvalue: 1.000)\n",
      "⚠ NMF does not support sample_weight\n",
      "⚠ NearestCentroid does not support sample_weight\n",
      "⚠ NeighborhoodComponentsAnalysis does not support sample_weight\n",
      "⚠ Normalizer does not support sample_weight\n",
      "Evaluating NuSVC(probability=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 166.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ NuSVC: (pvalue: 0.000)\n",
      "Evaluating NuSVR()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 285.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ NuSVR: (pvalue: 1.000)\n",
      "⚠ Nystroem does not support sample_weight\n",
      "⚠ OPTICS does not support sample_weight\n",
      "⚠ OneHotEncoder does not support sample_weight\n",
      "⚠ OneVsOneClassifier does not support sample_weight\n",
      "⚠ OneVsRestClassifier does not support sample_weight\n",
      "⚠ OrdinalEncoder does not support sample_weight\n",
      "⚠ OrthogonalMatchingPursuit does not support sample_weight\n",
      "⚠ OrthogonalMatchingPursuitCV does not support sample_weight\n",
      "⚠ OutputCodeClassifier does not support sample_weight\n",
      "⚠ PCA does not support sample_weight\n",
      "⚠ PLSCanonical does not support sample_weight\n",
      "⚠ PLSRegression does not support sample_weight\n",
      "⚠ PLSSVD does not support sample_weight\n",
      "⚠ PassiveAggressiveClassifier does not support sample_weight\n",
      "⚠ PassiveAggressiveRegressor does not support sample_weight\n",
      "⚠ PatchExtractor does not support sample_weight\n",
      "Evaluating Perceptron(max_iter=100000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 316.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Perceptron: (pvalue: 0.000)\n",
      "Evaluating PoissonRegressor()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 404.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PoissonRegressor: (pvalue: 1.000)\n",
      "⚠ PolynomialCountSketch does not support sample_weight\n",
      "⚠ PolynomialFeatures does not support sample_weight\n",
      "⚠ PowerTransformer does not support sample_weight\n",
      "⚠ QuadraticDiscriminantAnalysis does not support sample_weight\n",
      "Evaluating QuantileRegressor()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 160.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ QuantileRegressor: (pvalue: 1.000)\n",
      "⚠ QuantileTransformer does not support sample_weight\n",
      "Evaluating RANSACRegressor()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:00<00:02, 39.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ RANSACRegressor() error with: Weights sum to zero, can't be normalized\n",
      "⚠ RBFSampler does not support sample_weight\n",
      "⚠ RFE does not support sample_weight\n",
      "⚠ RFECV does not support sample_weight\n",
      "⚠ RadiusNeighborsClassifier does not support sample_weight\n",
      "⚠ RadiusNeighborsRegressor does not support sample_weight\n",
      "⚠ RadiusNeighborsTransformer does not support sample_weight\n",
      "Evaluating RandomForestClassifier()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ RandomForestClassifier: (pvalue: 0.000)\n",
      "Evaluating RandomForestRegressor(max_features=0.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ RandomForestRegressor: (pvalue: 0.000)\n",
      "Evaluating RandomTreesEmbedding(n_estimators=10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 90.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RandomTreesEmbedding: (pvalue: 0.968)\n",
      "⚠ RegressorChain does not support sample_weight\n",
      "Evaluating Ridge(max_iter=100000, solver='sag')\n",
      "❌ Ridge(max_iter=100000, solver='sag') error with: Floating-point under-/overflow occurred at epoch #10199. Scaling input data with StandardScaler or MinMaxScaler might help.\n",
      "Evaluating RidgeCV()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 101.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RidgeCV: (pvalue: 1.000)\n",
      "Evaluating RidgeClassifier(max_iter=100000, solver='saga')\n",
      "❌ RidgeClassifier(max_iter=100000, solver='saga') error with: Floating-point under-/overflow occurred at epoch #2233. Scaling input data with StandardScaler or MinMaxScaler might help.\n",
      "Evaluating RidgeClassifierCV()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 53.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RidgeClassifierCV: (pvalue: 1.000)\n",
      "⚠ RobustScaler does not support sample_weight\n",
      "Evaluating SGDClassifier(max_iter=100000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 301.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ SGDClassifier: (pvalue: 0.000)\n",
      "Evaluating SGDRegressor(max_iter=100000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1013.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ SGDRegressor: (pvalue: 0.000)\n",
      "Evaluating SVC(probability=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 176.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SVC: (pvalue: 0.001)\n",
      "Evaluating SVR()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 330.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SVR: (pvalue: 1.000)\n",
      "⚠ SelectFdr does not support sample_weight\n",
      "⚠ SelectFpr does not support sample_weight\n",
      "⚠ SelectFromModel does not support sample_weight\n",
      "⚠ SelectFwe does not support sample_weight\n",
      "⚠ SelectKBest does not support sample_weight\n",
      "⚠ SelectPercentile does not support sample_weight\n",
      "⚠ SelfTrainingClassifier does not support sample_weight\n",
      "⚠ SequentialFeatureSelector does not support sample_weight\n",
      "⚠ SimpleImputer does not support sample_weight\n",
      "⚠ SkewedChi2Sampler does not support sample_weight\n",
      "⚠ SparseCoder does not support sample_weight\n",
      "⚠ SparsePCA does not support sample_weight\n",
      "⚠ SparseRandomProjection does not support sample_weight\n",
      "⚠ SpectralClustering does not support sample_weight\n",
      "Evaluating SplineTransformer()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 198.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SplineTransformer: (pvalue: 1.000)\n",
      "⚠ StackingClassifier does not support sample_weight\n",
      "⚠ StackingRegressor does not support sample_weight\n",
      "Evaluating StandardScaler()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 523.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ StandardScaler: (pvalue: 1.000)\n",
      "⚠ TSNE does not support sample_weight\n",
      "⚠ TargetEncoder does not support sample_weight\n",
      "⚠ TfidfTransformer does not support sample_weight\n",
      "⚠ TheilSenRegressor does not support sample_weight\n",
      "⚠ TransformedTargetRegressor does not support sample_weight\n",
      "⚠ TruncatedSVD does not support sample_weight\n",
      "⚠ TunedThresholdClassifierCV does not support sample_weight\n",
      "Evaluating TweedieRegressor()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 476.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ TweedieRegressor: (pvalue: 1.000)\n",
      "⚠ VarianceThreshold does not support sample_weight\n",
      "⚠ VotingClassifier does not support sample_weight\n",
      "⚠ VotingRegressor does not support sample_weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N_STOCHASTIC_FITS = 100\n",
    "N_STATISTICAL_TESTS = 58  # measured by running the script\n",
    "BONFERRONI_CORRECTION = 1 / N_STATISTICAL_TESTS\n",
    "TEST_THRESHOLD = 0.05 * BONFERRONI_CORRECTION\n",
    "\n",
    "\n",
    "statistical_test_results = []\n",
    "missing_sample_weight_support = []\n",
    "errors = []\n",
    "\n",
    "\n",
    "for est_name, est_class in all_estimators(\n",
    "    type_filter=[\"classifier\", \"regressor\", \"cluster\", \"transformer\"]\n",
    "):\n",
    "    if est_class in ESTIMATORS_TO_SKIP:\n",
    "        print(f\"Skipping {est_name}\")\n",
    "        continue\n",
    "\n",
    "    if \"sample_weight\" not in signature(est_class.fit).parameters:\n",
    "        print(f\"⚠ {est_name} does not support sample_weight\")\n",
    "        missing_sample_weight_support.append(est_name)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        est = est_class(**STOCHASTIC_FIT_PARAMS.get(est_class, {}))\n",
    "    except TypeError as e:\n",
    "        print(f\"⚠ {est_name} failed to instantiate: {e}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Evaluating {est}\")\n",
    "    try:\n",
    "        result = check_weighted_repeated_estimator_fit_equivalence(\n",
    "            est,\n",
    "            est_name,\n",
    "            test_name=\"kstest\",\n",
    "            n_stochastic_fits=N_STOCHASTIC_FITS,\n",
    "            store_estimators=True,\n",
    "            random_state=0,\n",
    "        )\n",
    "        pass_or_fail = \"✅\" if result.pvalue > TEST_THRESHOLD else \"❌\"\n",
    "        print(f\"{pass_or_fail} {est_name}: (pvalue: {result.pvalue:.3f})\")\n",
    "        statistical_test_results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ {est} error with: {e}\")\n",
    "        errors.append((est, e))\n",
    "\n",
    "results_df = pd.DataFrame([r.to_dict() for r in statistical_test_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 45 passed the statistical test\n",
      "❌ 13 failed the statistical test\n",
      "❌ 4 other errors\n",
      "⚠ 116 estimators lack sample_weight support\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"✅ {len([r for r in statistical_test_results if r.pvalue > TEST_THRESHOLD])} \"\n",
    "    \"passed the statistical test\"\n",
    ")\n",
    "print(\n",
    "    f\"❌ {len([r for r in statistical_test_results if r.pvalue <= TEST_THRESHOLD])} \"\n",
    "    \"failed the statistical test\"\n",
    ")\n",
    "print(f\"❌ {len(errors)} other errors\")\n",
    "print(\n",
    "    f\"⚠ {len(missing_sample_weight_support)} estimators lack sample_weight \"\n",
    "    \"support\"\n",
    ")\n",
    "results_df = pd.DataFrame([r.to_dict() for r in statistical_test_results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Details on the statistical test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator_name</th>\n",
       "      <th>pvalue</th>\n",
       "      <th>deterministic_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>2.208761e-59</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>2.900986e-53</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>1.820209e-48</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>2.596277e-44</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>2.676640e-25</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NuSVC</td>\n",
       "      <td>3.357101e-13</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>1.070076e-12</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>1.115168e-08</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>6.617358e-08</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>7.850159e-06</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>3.211429e-05</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>LinearSVR</td>\n",
       "      <td>3.211429e-05</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>7.377026e-04</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>SVC</td>\n",
       "      <td>1.293506e-03</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>6.134033e-03</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>9.878183e-03</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>2.405580e-02</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>1.111953e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>2.111701e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>KBinsDiscretizer</td>\n",
       "      <td>2.819416e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ElasticNetCV</td>\n",
       "      <td>2.819416e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>2.819416e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>2.819416e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ExtraTreeRegressor</td>\n",
       "      <td>3.681878e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>5.830091e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>5.830091e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>7.020570e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>LassoCV</td>\n",
       "      <td>7.020570e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>8.154147e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>9.084105e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>9.684099e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>RandomTreesEmbedding</td>\n",
       "      <td>9.684099e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>QuantileRegressor</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ComplementNB</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CalibratedClassifierCV</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BisectingKMeans</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BayesianRidge</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>SVR</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>SplineTransformer</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>RidgeClassifierCV</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>PoissonRegressor</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GammaRegressor</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NuSVR</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>MiniBatchKMeans</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DummyRegressor</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>KernelRidge</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>KMeans</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>IsotonicRegression</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>HuberRegressor</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DBSCAN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>TweedieRegressor</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    estimator_name        pvalue  deterministic_predictions\n",
       "24  HistGradientBoostingClassifier  2.208761e-59                      False\n",
       "47           RandomForestRegressor  2.900986e-53                      False\n",
       "46          RandomForestClassifier  1.820209e-48                      False\n",
       "2                BaggingClassifier  2.596277e-44                      False\n",
       "36              LogisticRegression  2.676640e-25                      False\n",
       "41                           NuSVC  3.357101e-13                      False\n",
       "3                 BaggingRegressor  1.070076e-12                      False\n",
       "43                      Perceptron  1.115168e-08                      False\n",
       "51                   SGDClassifier  6.617358e-08                      False\n",
       "52                    SGDRegressor  7.850159e-06                      False\n",
       "25   HistGradientBoostingRegressor  3.211429e-05                      False\n",
       "35                       LinearSVR  3.211429e-05                      False\n",
       "1                AdaBoostRegressor  7.377026e-04                      False\n",
       "53                             SVC  1.293506e-03                      False\n",
       "23       GradientBoostingRegressor  6.134033e-03                      False\n",
       "34                       LinearSVC  9.878183e-03                      False\n",
       "12                 DummyClassifier  2.405580e-02                      False\n",
       "22      GradientBoostingClassifier  1.111953e-01                      False\n",
       "0               AdaBoostClassifier  2.111701e-01                      False\n",
       "28                KBinsDiscretizer  2.819416e-01                      False\n",
       "15                    ElasticNetCV  2.819416e-01                      False\n",
       "19             ExtraTreesRegressor  2.819416e-01                      False\n",
       "10          DecisionTreeClassifier  2.819416e-01                      False\n",
       "17              ExtraTreeRegressor  3.681878e-01                      False\n",
       "11           DecisionTreeRegressor  5.830091e-01                      False\n",
       "14                      ElasticNet  5.830091e-01                      False\n",
       "37                   MLPClassifier  7.020570e-01                      False\n",
       "32                         LassoCV  7.020570e-01                      False\n",
       "18            ExtraTreesClassifier  8.154147e-01                      False\n",
       "38                    MLPRegressor  9.084105e-01                      False\n",
       "16             ExtraTreeClassifier  9.684099e-01                      False\n",
       "48            RandomTreesEmbedding  9.684099e-01                      False\n",
       "45               QuantileRegressor  1.000000e+00                       True\n",
       "8                     ComplementNB  1.000000e+00                       True\n",
       "7           CalibratedClassifierCV  1.000000e+00                       True\n",
       "49                         RidgeCV  1.000000e+00                       True\n",
       "6                  BisectingKMeans  1.000000e+00                      False\n",
       "5                      BernoulliNB  1.000000e+00                       True\n",
       "4                    BayesianRidge  1.000000e+00                       True\n",
       "54                             SVR  1.000000e+00                       True\n",
       "55               SplineTransformer  1.000000e+00                       True\n",
       "50               RidgeClassifierCV  1.000000e+00                       True\n",
       "44                PoissonRegressor  1.000000e+00                       True\n",
       "20                  GammaRegressor  1.000000e+00                       True\n",
       "42                           NuSVR  1.000000e+00                       True\n",
       "40                   MultinomialNB  1.000000e+00                       True\n",
       "39                 MiniBatchKMeans  1.000000e+00                      False\n",
       "13                  DummyRegressor  1.000000e+00                       True\n",
       "33                LinearRegression  1.000000e+00                       True\n",
       "31                           Lasso  1.000000e+00                       True\n",
       "30                     KernelRidge  1.000000e+00                       True\n",
       "29                          KMeans  1.000000e+00                      False\n",
       "56                  StandardScaler  1.000000e+00                       True\n",
       "27              IsotonicRegression  1.000000e+00                       True\n",
       "26                  HuberRegressor  1.000000e+00                       True\n",
       "21                      GaussianNB  1.000000e+00                       True\n",
       "9                           DBSCAN  1.000000e+00                      False\n",
       "57                TweedieRegressor  1.000000e+00                       True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(\"pvalue\")[[\"estimator_name\", \"pvalue\", \"deterministic_predictions\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=0),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=1),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=2),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=3),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=4),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=5),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=6),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=7),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=8),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=9),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=10),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=11),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=12),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=13),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=14),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=15),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=16),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=17),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=18),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=19),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=20),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=21),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=22),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=23),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=24),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=25),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=26),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=27),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=28),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=29),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=30),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=31),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=32),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=33),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=34),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=35),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=36),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=37),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=38),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=39),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=40),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=41),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=42),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=43),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=44),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=45),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=46),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=47),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=48),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=49),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=50),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=51),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=52),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=53),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=54),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=55),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=56),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=57),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=58),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=59),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=60),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=61),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=62),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=63),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=64),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=65),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=66),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=67),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=68),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=69),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=70),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=71),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=72),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=73),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=74),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=75),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=76),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=77),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=78),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=79),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=80),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=81),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=82),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=83),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=84),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=85),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=86),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=87),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=88),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=89),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=90),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=91),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=92),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=93),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=94),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=95),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=96),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=97),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=98),\n",
       " AdaBoostClassifier(estimator=DecisionTreeClassifier(max_features=0.5,\n",
       "                                                     min_weight_fraction_leaf=0.1),\n",
       "                    random_state=99)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.iloc[0]['estimators_weighted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Details on errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ CategoricalNB(): index 7 is out of bounds for axis 1 with size 7\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/h4/l_wtcs4s43j2j9454pvp1c580000gn/T/ipykernel_41249/3518123444.py\", line 32, in <module>\n",
      "    result = check_weighted_repeated_estimator_fit_equivalence(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shrutinath/sample_weight_audit_dist/src/sample_weight_audit/estimator_check.py\", line 97, in check_weighted_repeated_estimator_fit_equivalence\n",
      "    multifit_results = multifit_over_weighted_and_repeated(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shrutinath/sample_weight_audit_dist/src/sample_weight_audit/estimator_check.py\", line 372, in multifit_over_weighted_and_repeated\n",
      "    scores_weighted, preds_weighted = score_estimator(\n",
      "                                      ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shrutinath/sample_weight_audit_dist/src/sample_weight_audit/estimator_check.py\", line 204, in score_estimator\n",
      "    preds = est.predict_proba(X).round(decimals)\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/naive_bayes.py\", line 148, in predict_proba\n",
      "    return np.exp(self.predict_log_proba(X))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/naive_bayes.py\", line 127, in predict_log_proba\n",
      "    jll = self._joint_log_likelihood(X)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/naive_bayes.py\", line 1537, in _joint_log_likelihood\n",
      "    jll += self.feature_log_prob_[i][:, indices].T\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "IndexError: index 7 is out of bounds for axis 1 with size 7\n",
      "\n",
      "❌ RANSACRegressor(): Weights sum to zero, can't be normalized\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/h4/l_wtcs4s43j2j9454pvp1c580000gn/T/ipykernel_41249/3518123444.py\", line 32, in <module>\n",
      "    result = check_weighted_repeated_estimator_fit_equivalence(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shrutinath/sample_weight_audit_dist/src/sample_weight_audit/estimator_check.py\", line 97, in check_weighted_repeated_estimator_fit_equivalence\n",
      "    multifit_results = multifit_over_weighted_and_repeated(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shrutinath/sample_weight_audit_dist/src/sample_weight_audit/estimator_check.py\", line 358, in multifit_over_weighted_and_repeated\n",
      "    est_weighted = check_pipeline_and_fit(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shrutinath/sample_weight_audit_dist/src/sample_weight_audit/estimator_check.py\", line 262, in check_pipeline_and_fit\n",
      "    est = est.fit(X, y, sample_weight=sample_weight)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/base.py\", line 1363, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_ransac.py\", line 493, in fit\n",
      "    estimator.fit(X_subset, y_subset, **fit_params_subset)\n",
      "  File \"/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/base.py\", line 1363, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_base.py\", line 639, in fit\n",
      "    X, y, X_offset, y_offset, X_scale = _preprocess_data(\n",
      "                                        ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_base.py\", line 185, in _preprocess_data\n",
      "    X_offset = _average(X, axis=0, weights=sample_weight, xp=xp)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/utils/_array_api.py\", line 617, in _average\n",
      "    return xp.asarray(numpy.average(a, axis=axis, weights=weights))\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shrutinath/micromamba/envs/scikit-learn/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py\", line 570, in average\n",
      "    raise ZeroDivisionError(\n",
      "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
      "\n",
      "❌ Ridge(max_iter=100000, solver='sag'): Floating-point under-/overflow occurred at epoch #10199. Scaling input data with StandardScaler or MinMaxScaler might help.\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/h4/l_wtcs4s43j2j9454pvp1c580000gn/T/ipykernel_41249/3518123444.py\", line 32, in <module>\n",
      "    result = check_weighted_repeated_estimator_fit_equivalence(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shrutinath/sample_weight_audit_dist/src/sample_weight_audit/estimator_check.py\", line 97, in check_weighted_repeated_estimator_fit_equivalence\n",
      "    multifit_results = multifit_over_weighted_and_repeated(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shrutinath/sample_weight_audit_dist/src/sample_weight_audit/estimator_check.py\", line 330, in multifit_over_weighted_and_repeated\n",
      "    est_ref = check_pipeline_and_fit(est_ref, X_train, y_train, sample_weight_train)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shrutinath/sample_weight_audit_dist/src/sample_weight_audit/estimator_check.py\", line 262, in check_pipeline_and_fit\n",
      "    est = est.fit(X, y, sample_weight=sample_weight)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/base.py\", line 1363, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_ridge.py\", line 1248, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_ridge.py\", line 990, in fit\n",
      "    self.coef_, self.n_iter_, self.solver_ = _ridge_regression(\n",
      "                                             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_ridge.py\", line 765, in _ridge_regression\n",
      "    coef_, n_iter_, _ = sag_solver(\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_sag.py\", line 323, in sag_solver\n",
      "    num_seen, n_iter_ = sag(\n",
      "                        ^^^^\n",
      "  File \"sklearn/linear_model/_sag_fast.pyx\", line 396, in sklearn.linear_model._sag_fast.sag64\n",
      "ValueError: Floating-point under-/overflow occurred at epoch #10199. Scaling input data with StandardScaler or MinMaxScaler might help.\n",
      "\n",
      "❌ RidgeClassifier(max_iter=100000, solver='saga'): Floating-point under-/overflow occurred at epoch #2233. Scaling input data with StandardScaler or MinMaxScaler might help.\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/h4/l_wtcs4s43j2j9454pvp1c580000gn/T/ipykernel_41249/3518123444.py\", line 32, in <module>\n",
      "    result = check_weighted_repeated_estimator_fit_equivalence(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shrutinath/sample_weight_audit_dist/src/sample_weight_audit/estimator_check.py\", line 97, in check_weighted_repeated_estimator_fit_equivalence\n",
      "    multifit_results = multifit_over_weighted_and_repeated(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shrutinath/sample_weight_audit_dist/src/sample_weight_audit/estimator_check.py\", line 330, in multifit_over_weighted_and_repeated\n",
      "    est_ref = check_pipeline_and_fit(est_ref, X_train, y_train, sample_weight_train)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shrutinath/sample_weight_audit_dist/src/sample_weight_audit/estimator_check.py\", line 262, in check_pipeline_and_fit\n",
      "    est = est.fit(X, y, sample_weight=sample_weight)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/base.py\", line 1363, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_ridge.py\", line 1570, in fit\n",
      "    super().fit(X, Y, sample_weight=sample_weight)\n",
      "  File \"/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_ridge.py\", line 990, in fit\n",
      "    self.coef_, self.n_iter_, self.solver_ = _ridge_regression(\n",
      "                                             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_ridge.py\", line 765, in _ridge_regression\n",
      "    coef_, n_iter_, _ = sag_solver(\n",
      "                        ^^^^^^^^^^^\n",
      "  File \"/Users/shrutinath/sklearn-dev/scikit-learn/sklearn/linear_model/_sag.py\", line 323, in sag_solver\n",
      "    num_seen, n_iter_ = sag(\n",
      "                        ^^^^\n",
      "  File \"sklearn/linear_model/_sag_fast.pyx\", line 396, in sklearn.linear_model._sag_fast.sag64\n",
      "ValueError: Floating-point under-/overflow occurred at epoch #2233. Scaling input data with StandardScaler or MinMaxScaler might help.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "for est, e in errors:\n",
    "    print(f\"❌ {est}: {e}\")\n",
    "    traceback.print_exception(e, file=sys.stdout)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of estimators with missing sample_weight support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARDRegression\n",
      "AdditiveChi2Sampler\n",
      "AffinityPropagation\n",
      "AgglomerativeClustering\n",
      "BernoulliRBM\n",
      "Binarizer\n",
      "Birch\n",
      "CCA\n",
      "ClassifierChain\n",
      "ColumnTransformer\n",
      "DictVectorizer\n",
      "DictionaryLearning\n",
      "FactorAnalysis\n",
      "FastICA\n",
      "FeatureAgglomeration\n",
      "FeatureHasher\n",
      "FeatureUnion\n",
      "FixedThresholdClassifier\n",
      "FunctionTransformer\n",
      "GaussianProcessClassifier\n",
      "GaussianProcessRegressor\n",
      "GaussianRandomProjection\n",
      "GenericUnivariateSelect\n",
      "HDBSCAN\n",
      "HashingVectorizer\n",
      "IncrementalPCA\n",
      "Isomap\n",
      "KNNImputer\n",
      "KNeighborsClassifier\n",
      "KNeighborsRegressor\n",
      "KNeighborsTransformer\n",
      "KernelCenterer\n",
      "KernelPCA\n",
      "LabelBinarizer\n",
      "LabelEncoder\n",
      "LabelPropagation\n",
      "LabelSpreading\n",
      "Lars\n",
      "LarsCV\n",
      "LassoLars\n",
      "LassoLarsCV\n",
      "LassoLarsIC\n",
      "LatentDirichletAllocation\n",
      "LinearDiscriminantAnalysis\n",
      "LocallyLinearEmbedding\n",
      "MaxAbsScaler\n",
      "MeanShift\n",
      "MinMaxScaler\n",
      "MiniBatchDictionaryLearning\n",
      "MiniBatchNMF\n",
      "MiniBatchSparsePCA\n",
      "MissingIndicator\n",
      "MultiLabelBinarizer\n",
      "MultiTaskElasticNet\n",
      "MultiTaskElasticNetCV\n",
      "MultiTaskLasso\n",
      "MultiTaskLassoCV\n",
      "NMF\n",
      "NearestCentroid\n",
      "NeighborhoodComponentsAnalysis\n",
      "Normalizer\n",
      "Nystroem\n",
      "OPTICS\n",
      "OneHotEncoder\n",
      "OneVsOneClassifier\n",
      "OneVsRestClassifier\n",
      "OrdinalEncoder\n",
      "OrthogonalMatchingPursuit\n",
      "OrthogonalMatchingPursuitCV\n",
      "OutputCodeClassifier\n",
      "PCA\n",
      "PLSCanonical\n",
      "PLSRegression\n",
      "PLSSVD\n",
      "PassiveAggressiveClassifier\n",
      "PassiveAggressiveRegressor\n",
      "PatchExtractor\n",
      "PolynomialCountSketch\n",
      "PolynomialFeatures\n",
      "PowerTransformer\n",
      "QuadraticDiscriminantAnalysis\n",
      "QuantileTransformer\n",
      "RBFSampler\n",
      "RFE\n",
      "RFECV\n",
      "RadiusNeighborsClassifier\n",
      "RadiusNeighborsRegressor\n",
      "RadiusNeighborsTransformer\n",
      "RegressorChain\n",
      "RobustScaler\n",
      "SelectFdr\n",
      "SelectFpr\n",
      "SelectFromModel\n",
      "SelectFwe\n",
      "SelectKBest\n",
      "SelectPercentile\n",
      "SelfTrainingClassifier\n",
      "SequentialFeatureSelector\n",
      "SimpleImputer\n",
      "SkewedChi2Sampler\n",
      "SparseCoder\n",
      "SparsePCA\n",
      "SparseRandomProjection\n",
      "SpectralClustering\n",
      "StackingClassifier\n",
      "StackingRegressor\n",
      "TSNE\n",
      "TargetEncoder\n",
      "TfidfTransformer\n",
      "TheilSenRegressor\n",
      "TransformedTargetRegressor\n",
      "TruncatedSVD\n",
      "TunedThresholdClassifierCV\n",
      "VarianceThreshold\n",
      "VotingClassifier\n",
      "VotingRegressor\n"
     ]
    }
   ],
   "source": [
    "for est_name in missing_sample_weight_support:\n",
    "    print(est_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example interactive inspection of the predictions and scores of a given estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = next(r for r in statistical_test_results if r.estimator_name == \"GaussianNB\")\n",
    "results.predictions_repeated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.predictions_weighted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.9999992207384594e-10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.abs(results.predictions_repeated - results.predictions_weighted).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.2652280879119644e-10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(results.scores_repeated - results.scores_weighted).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KstestResult(statistic=np.float64(1.0), pvalue=np.float64(1.0), statistic_location=np.float64(3.262703314947884), statistic_sign=np.int8(1))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import kstest\n",
    "kstest(results.scores_repeated, results.scores_weighted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
