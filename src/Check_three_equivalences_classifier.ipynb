{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"SCIPY_ARRAY_API\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "from inspect import signature\n",
    "from sklearn.utils import all_estimators\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import threadpoolctl\n",
    "\n",
    "from sample_weight_audit import check_weighted_repeated_estimator_fit_equivalence\n",
    "from sample_weight_audit.sklearn_stochastic_params import STOCHASTIC_FIT_PARAMS \n",
    "\n",
    "\n",
    "threadpoolctl.threadpool_limits(limits=1, user_api=\"openmp\")  # HistGradientBoostingClassifier is trashing.\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)  # division by zero in AdaBoost\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)  # Liblinear can fail to converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating AdaBoostClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:02<00:00, 10.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ AdaBoostClassifier with different random states led to the same predictions\n",
      "Evaluating AdaBoostRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:02<00:00, 11.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ AdaBoostRegressor: (min_p_value: 0.135, mean_p_value=0.724)\n",
      "Evaluating BaggingClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 46.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ BaggingClassifier: (min_p_value: 0.000, mean_p_value=0.324)\n",
      "Evaluating BaggingRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 34.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ BaggingRegressor: (min_p_value: 0.000, mean_p_value=0.214)\n",
      "❌ BernoulliRBM does not support sample_weight\n",
      "Evaluating BisectingKMeans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 126.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ BisectingKMeans with different random states led to the same predictions\n",
      "❌ ClassifierChain does not support sample_weight\n",
      "Evaluating DecisionTreeClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 265.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DecisionTreeClassifier: (min_p_value: 1.000, mean_p_value=1.000)\n",
      "Evaluating DecisionTreeRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 334.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ DecisionTreeRegressor: (min_p_value: 0.007, mean_p_value=0.435)\n",
      "❌ DictionaryLearning does not support sample_weight\n",
      "Evaluating DummyClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 533.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DummyClassifier: (min_p_value: 1.000, mean_p_value=1.000)\n",
      "Evaluating ElasticNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 444.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ElasticNet: (min_p_value: 1.000, mean_p_value=1.000)\n",
      "Evaluating ElasticNetCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:01<00:00, 27.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ElasticNetCV: (min_p_value: 1.000, mean_p_value=1.000)\n",
      "Evaluating ExtraTreeClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 621.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ExtraTreeClassifier: (min_p_value: 1.000, mean_p_value=1.000)\n",
      "Evaluating ExtraTreeRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 692.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ExtraTreeRegressor: (min_p_value: 0.393, mean_p_value=0.752)\n",
      "Evaluating ExtraTreesClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:03<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ExtraTreesClassifier: (min_p_value: 1.000, mean_p_value=1.000)\n",
      "Evaluating ExtraTreesRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:03<00:00,  8.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ExtraTreesRegressor: (min_p_value: 0.135, mean_p_value=0.629)\n",
      "❌ FactorAnalysis does not support sample_weight\n",
      "❌ FastICA does not support sample_weight\n",
      "❌ GaussianProcessClassifier does not support sample_weight\n",
      "❌ GaussianProcessRegressor does not support sample_weight\n",
      "❌ GaussianRandomProjection does not support sample_weight\n",
      "Evaluating GradientBoostingClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:07<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GradientBoostingClassifier: (min_p_value: 0.239, mean_p_value=0.932)\n",
      "Evaluating GradientBoostingRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:01<00:00, 21.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GradientBoostingRegressor: (min_p_value: 0.393, mean_p_value=0.833)\n",
      "Evaluating HistGradientBoostingClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:03<00:00,  9.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ HistGradientBoostingClassifier: (min_p_value: 0.000, mean_p_value=0.055)\n",
      "Evaluating HistGradientBoostingRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:01<00:00, 27.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ HistGradientBoostingRegressor: (min_p_value: 0.000, mean_p_value=0.092)\n",
      "Evaluating KBinsDiscretizer\n",
      "❌ KBinsDiscretizer with different random states led to the same predictions\n",
      "Evaluating KMeans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 359.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ KMeans with different random states led to the same predictions\n",
      "❌ KernelPCA does not support sample_weight\n",
      "❌ Lars does not support sample_weight\n",
      "Evaluating Lasso\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 303.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Lasso: (min_p_value: 1.000, mean_p_value=1.000)\n",
      "Evaluating LassoCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 30.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LassoCV: (min_p_value: 1.000, mean_p_value=1.000)\n",
      "❌ LassoLars does not support sample_weight\n",
      "❌ LatentDirichletAllocation does not support sample_weight\n",
      "Evaluating LinearSVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 53.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ LinearSVC: (min_p_value: 0.000, mean_p_value=0.000)\n",
      "Evaluating LinearSVR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 333.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ LinearSVR: (min_p_value: 0.000, mean_p_value=0.011)\n",
      "❌ LocallyLinearEmbedding does not support sample_weight\n",
      "Evaluating LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 73.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ LogisticRegression: (min_p_value: 0.000, mean_p_value=0.113)\n",
      "Evaluating LogisticRegressionCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [02:17<01:32,  7.69s/it]"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "# XXX: how to handle clustering estimators?\n",
    "for est_name, est_class in all_estimators(\n",
    "    type_filter=[\"classifier\", \"regressor\", \"transformer\"]\n",
    "):\n",
    "    if \"random_state\" not in signature(est_class.__init__).parameters:\n",
    "        # Skip estimators with a deterministic fit: they are better tested via\n",
    "        # the check_sample_weight_equivalence_on_dense_data estimator check run\n",
    "        # as part of the scikit-learn test suite.\n",
    "        continue\n",
    "\n",
    "    if \"sample_weight\" not in signature(est_class.fit).parameters:\n",
    "        print(f\"❌ {est_name} does not support sample_weight\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Evaluating {est_name}\")\n",
    "    est = est_class(**STOCHASTIC_FIT_PARAMS.get(est_class, {}))\n",
    "    try:\n",
    "        result = check_weighted_repeated_estimator_fit_equivalence(\n",
    "            est,\n",
    "            test_name=\"kstest\",\n",
    "            n_stochastic_fits=30,\n",
    "        )\n",
    "        pass_or_fail = \"✅\" if result.min_p_value > 0.05 else \"❌\"\n",
    "        print(\n",
    "            f\"{pass_or_fail} {est_name}: (min_p_value: {result.min_p_value:.3f}, \"\n",
    "            f\"mean_p_value={result.mean_p_value:.3f})\"\n",
    "        )\n",
    "        results.append(result)\n",
    "    except ValueError:\n",
    "        # XXX: Use the deterministic check instead?\n",
    "        print(f\"❌ {est_name} with different random states led to the same predictions\")\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame([r.to_dict() for r in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.sort_values(\"min_p_value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
